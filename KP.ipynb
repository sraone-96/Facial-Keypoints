{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.regularizers import *\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting training data and creating X,Y\n",
    "with open('training.csv','r')as f:\n",
    "        lines=f.readlines()\n",
    "Y=[]\n",
    "features=lines.pop(0)\n",
    "X=[]\n",
    "for eachline in lines:\n",
    "    temp1=str.split(eachline,',')\n",
    "    temp2=temp1[0:30]\n",
    "    Y.append(temp2)\n",
    "    temp3=str.split(temp1[30],' ')\n",
    "    X.append(temp3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "X=X.astype('float')\n",
    "\n",
    "#--------------------Fill missing Values in gicen data by using AVERAGES-------------------------------#\n",
    "# avg=np.zeros(30)\n",
    "# nums=np.zeros(30)\n",
    "# for i in range(len(Y)):\n",
    "#     for j in range(len(Y[i])):\n",
    "#         if(Y[i][j]):\n",
    "#                    avg[j]=avg[j]+(float)(Y[i][j])\n",
    "#                    nums[j]=nums[j]+1\n",
    "# avg=np.divide(avg,nums)\n",
    "#print avg\n",
    "X_final=[]\n",
    "Y_final=[]\n",
    "for i in range(len(Y)):\n",
    "    flag=0\n",
    "    for j in range(len(Y[i])):\n",
    "        if(Y[i][j]==\"\"):\n",
    "            flag=1\n",
    "            break\n",
    "    if(flag==0):\n",
    "        X_final.append(X[i])\n",
    "        Y_final.append(Y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 9216)\n",
      "(2140, 30)\n"
     ]
    }
   ],
   "source": [
    "#--------------------Data has lot of missing Points-----------------------------------------#\n",
    "#-----------------Using average to fill them is reducing accuracy---------------------------#\n",
    "\n",
    "# X_final and Y_final are arrays which do not have those data where the keypoints are missing\n",
    "\n",
    "print np.shape(X_final)\n",
    "print np.shape(Y_final)\n",
    "\n",
    "X_final=np.array(X_final)\n",
    "Y_final=np.array(Y_final)\n",
    "X_final=X_final.astype('float')\n",
    "Y_final=Y_final.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 96, 96, 1)\n",
      "(2140, 30)\n"
     ]
    }
   ],
   "source": [
    "#----------X_new is the input data to the MODEL--------------#\n",
    "X_new=[]\n",
    "for eachimage in X_final:\n",
    "    temp=np.reshape(eachimage,(96,96,1))\n",
    "    X_new.append(temp)\n",
    "X_new=np.array(X_new)\n",
    "X_new=X_new.astype('float')\n",
    "\n",
    "print np.shape(X_new)\n",
    "print np.shape(Y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Data modification for UNET ARCHITECTURE------------------------------#\n",
    "\n",
    "\n",
    "# points=np.zeros((len(X_new),96,96,15))\n",
    "# #import math\n",
    "# for i in range(len(X_new)):\n",
    "#     for j in range(0,30,2):\n",
    "#         a=int(Y_final[i][j])\n",
    "#         b=int(Y_final[i][j+1])\n",
    "#         points[i][a][b][j/2]=255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f16d650da90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16dc668890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temps=points[0]\n",
    "# l=temps[:,:,1]\n",
    "# print np.shape(l)\n",
    "# plt.imshow(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7049, 9216)\n",
      "(7049, 30)\n",
      "(2140, 96, 96, 15)\n"
     ]
    }
   ],
   "source": [
    "# print np.shape(X)\n",
    "# print np.shape(Y)\n",
    "# print np.shape(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "\n",
    "    \n",
    "    #---------------------------MODEL SUBMITTED FOR THE CONTEST--------------------------#\n",
    "\n",
    "    input_image1=Input(shape=(96,96,1))\n",
    "    input_image=BatchNormalization()(input_image1)\n",
    "    conv1_32 = Conv2D(8,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(input_image)\n",
    "    conv1_32 = BatchNormalization()(conv1_32)\n",
    "    \n",
    "    conv2_64 = Conv2D(16,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(conv1_32)\n",
    "    conv2_64 = Conv2D(16,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv2_64)    \n",
    "    conv2_64 = AveragePooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv2_64)\n",
    "    conv2_64 = BatchNormalization()(conv2_64)\n",
    "    \n",
    "    conv3_128 = Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv2_64)\n",
    "    conv3_128 = Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv3_128)\n",
    "    conv3_128 = AveragePooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv3_128)\n",
    "    conv3_128 = BatchNormalization()(conv3_128)\n",
    "    \n",
    "    conv4_256 = Conv2D(64,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv3_128)\n",
    "    conv4_256 = Conv2D(128,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv4_256)\n",
    "    conv4_256 = AveragePooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv4_256)\n",
    "    conv4_256 = BatchNormalization()(conv4_256)\n",
    "    \n",
    "    conv5_512 = Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv4_256)\n",
    "    conv5_512 = Conv2D(128,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv5_512)\n",
    "    conv5_512 = AveragePooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv5_512)\n",
    "    conv5_512 = BatchNormalization()(conv5_512)\n",
    "    \n",
    "\n",
    "    \n",
    "    penultimate_layer=Flatten()(conv5_512)\n",
    "    final_dense2=Dense(64, activation='relu')(penultimate_layer)\n",
    "    outputs=Dense(30, activation='relu')(penultimate_layer)\n",
    "\n",
    "    model = Model(inputs=input_image1,outputs=outputs)\n",
    "\n",
    "    return model\n",
    "#    SCORE=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "#--------------------U net architecture with skip connections----------------------#\n",
    "#--------------------Input data has been changed in above CELSS which are commented for now--------------------#\n",
    "#ENCODER\n",
    "    input_image=Input(shape=(96,96,1))\n",
    "    conv1_32 = Conv2D(32,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.0001))(input_image)\n",
    "    conv1_32 = Conv2D(32,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.0001))(conv1_32)\n",
    "    \n",
    "    conv2_64 = MaxPooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv1_32)\n",
    "    conv2_64 = BatchNormalization()(conv2_64)\n",
    "    conv2_64 = Conv2D(64,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(conv2_64)\n",
    "    conv2_64 = Conv2D(64,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.001))(conv2_64)    \n",
    "    \n",
    "    conv3_128 = MaxPooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv2_64)\n",
    "    #conv3_128=Dropout(0.2)(conv3_128)\n",
    "    conv3_128 = BatchNormalization()(conv3_128)\n",
    "    conv3_128 = Conv2D(128,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.0001))(conv3_128)\n",
    "    conv3_128 = Conv2D(128,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.0001))(conv3_128)\n",
    "    \n",
    "    conv4_256 = MaxPooling2D(pool_size=(2,2),strides=2,padding=\"same\")(conv3_128)\n",
    "    conv4_256 = BatchNormalization()(conv4_256)\n",
    "    conv4_256 = Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.0001))(conv4_256)\n",
    "    conv4_256 = Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',kernel_regularizer=l2(0.0001))(conv4_256)\n",
    "    \n",
    "    \n",
    "#DECODER\n",
    "    \n",
    "    deconv5_512 = Conv2DTranspose(256,kernel_size=(3,3),strides=2,padding='same',activation='relu',kernel_regularizer=l2(0.001))(conv4_256)\n",
    "    deconv5_512 = BatchNormalization()(deconv5_512)\n",
    "    deconv5_512 = Concatenate()([deconv5_512,conv3_128])\n",
    "    deconv5_512 = Conv2D(256,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(deconv5_512)\n",
    "\n",
    "\n",
    "    deconv4_256 = Conv2DTranspose(128,kernel_size=(3,3),strides=2,padding='same',activation='relu',kernel_regularizer=l2(0.001))(deconv5_512)\n",
    "    deconv4_256 = BatchNormalization()(deconv4_256)\n",
    "    deconv4_256 = Concatenate()([deconv4_256,conv2_64])\n",
    "    deconv4_256 = Conv2D(128,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(deconv4_256)\n",
    "\n",
    "    deconv3_128 = Conv2DTranspose(64,kernel_size=(3,3),strides=2,padding='same',activation='relu',kernel_regularizer=l2(0.001))(deconv4_256)\n",
    "    deconv3_128 = BatchNormalization()(deconv3_128)\n",
    "    deconv3_128 = Concatenate()([deconv3_128,conv1_32])\n",
    "    deconv3_128 = Conv2D(15,kernel_size=(3,3),padding='same',activation='relu',kernel_regularizer=l2(0.001))(deconv3_128)\n",
    "\n",
    "    model = Model(inputs=input_image,outputs=deconv3_128)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 96, 96, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 96, 96, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 96, 96, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 96, 96, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 96, 96, 16)        2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 12, 12, 128)       295040    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                138270    \n",
      "=================================================================\n",
      "Total params: 839,538\n",
      "Trainable params: 838,912\n",
      "Non-trainable params: 626\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#-------------------------Model Compilation and Summary-------------------------#\n",
    "gen=generator_model()\n",
    "gen.summary()\n",
    "gen.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2140/2140 [==============================] - 3s 2ms/step - loss: 499.6662 - acc: 0.5771\n",
      "Epoch 2/5\n",
      "2140/2140 [==============================] - 1s 469us/step - loss: 11.0392 - acc: 0.7051\n",
      "Epoch 3/5\n",
      "2140/2140 [==============================] - 1s 473us/step - loss: 7.1179 - acc: 0.7047\n",
      "Epoch 4/5\n",
      "2140/2140 [==============================] - 1s 470us/step - loss: 5.5958 - acc: 0.7107\n",
      "Epoch 5/5\n",
      "2140/2140 [==============================] - 1s 480us/step - loss: 4.5833 - acc: 0.7178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6098f63b90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gen.fit(X_new,Y_final,epochs=5, verbose=1,batch_size=64,validation_split=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 1)\n",
      "(1783, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "#-----------------Testing on test data and creating submsiision File-------------------------#\n",
    "\n",
    "imageid=[]\n",
    "rowid=0\n",
    "with open('test.csv','r') as f:\n",
    "    l=f.readlines()\n",
    "    l.pop(0)\n",
    "#print l[0]\n",
    "Testing=[]\n",
    "for eachline in l:\n",
    "    tempo=str.split(eachline,',')\n",
    "    imageid.append(tempo[0])\n",
    "    temp1=str.split(tempo[1])\n",
    "    temp=np.asarray(temp1)\n",
    "    Testing.append(temp)\n",
    "Testing=np.asarray(Testing)\n",
    "\n",
    "testing=[]\n",
    "for images in Testing:\n",
    "    temp=np.reshape(images,(96,96,1))\n",
    "    testing.append(temp)\n",
    "print np.shape(temp)\n",
    "testing=np.array(testing)\n",
    "testing=testing.astype('float')\n",
    "print np.shape(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Output Prediction---------------------#\n",
    "OUT=gen.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowid=0\n",
    "rowid=rowid+1\n",
    "with open('training.csv','r')as f:\n",
    "        lines=f.readlines()\n",
    "features=lines.pop(0)\n",
    "features=str.split(features,',')\n",
    "o=features.pop(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submision.csv','w+') as f:\n",
    "    f.write(\"RowId,Location\\n\")\n",
    "\n",
    "with open('IdLookupTable.csv','r')as g:\n",
    "    m=g.readlines()\n",
    "    m.pop(0)\n",
    "    for eachline in m:\n",
    "        strs=str.split(eachline,',')\n",
    "        rowid=int(strs[0])\n",
    "        imgid=int(strs[1])\n",
    "        #print imgid\n",
    "        #print strs[2]\n",
    "        for j in range(len(features)):\n",
    "            if(j==strs[2]):\n",
    "                break\n",
    "        if(OUT[imgid-1][j]>96):\n",
    "            OUT[imgid-1][j]=96\n",
    "        with open('submision.csv','a') as f:\n",
    "            f.write(\"%d,%f\\n\" %(rowid,OUT[imgid-1][j]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
